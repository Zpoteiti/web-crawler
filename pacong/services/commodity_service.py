"""
å•†å“æ•°æ®æœåŠ¡
æä¾›é«˜çº§çš„å•†å“æ•°æ®è·å–å’Œå¤„ç†åŠŸèƒ½
"""

from typing import List, Dict, Any, Optional, Union
from datetime import datetime
from pathlib import Path

from ..core import get_logger, get_config
from ..data import CommodityData, DataProcessor, DataValidator
from ..scrapers import ScraperFactory
from ..output.csv_writer import CSVWriter
from ..output.excel_writer import ExcelWriter


class CommodityService:
    """å•†å“æ•°æ®æœåŠ¡"""
    
    def __init__(self):
        self.logger = get_logger(__name__)
        self.config = get_config()
        self.data_processor = DataProcessor()
        self.data_validator = DataValidator()
        
        # è¾“å‡ºç›®å½•
        self.output_dir = Path(self.config.output.reports_dir)
        self.output_dir.mkdir(exist_ok=True)
        
        self.logger.info("å•†å“æ•°æ®æœåŠ¡åˆå§‹åŒ–å®Œæˆ")
    
    def collect_all_commodity_data(self, scraper_names: Optional[List[str]] = None) -> List[CommodityData]:
        """
        æ”¶é›†æ‰€æœ‰å•†å“æ•°æ®
        
        Args:
            scraper_names: è¦ä½¿ç”¨çš„çˆ¬è™«åç§°åˆ—è¡¨ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨æ‰€æœ‰å¯ç”¨çˆ¬è™«
            
        Returns:
            List[CommodityData]: å•†å“æ•°æ®åˆ—è¡¨
        """
        self.logger.info("ğŸš€ å¼€å§‹æ”¶é›†å•†å“æ•°æ®")
        
        # è·å–çˆ¬è™«åˆ—è¡¨
        if scraper_names is None:
            scraper_names = ScraperFactory.list_available_scrapers()
        
        all_raw_data = []
        
        # ä½¿ç”¨æ¯ä¸ªçˆ¬è™«æ”¶é›†æ•°æ®
        for scraper_name in scraper_names:
            try:
                self.logger.info(f"ğŸ“Š ä½¿ç”¨çˆ¬è™«: {scraper_name}")
                
                with ScraperFactory.create_scraper(scraper_name) as scraper:
                    if scraper:
                        raw_data = scraper.scrape_all()
                        all_raw_data.extend(raw_data)
                        
                        self.logger.info(f"âœ… {scraper_name}: è·å– {len(raw_data)} æ¡åŸå§‹æ•°æ®")
                    else:
                        self.logger.warning(f"âš ï¸ æ— æ³•åˆ›å»ºçˆ¬è™«: {scraper_name}")
                        
            except Exception as e:
                self.logger.error(f"âŒ çˆ¬è™« {scraper_name} æ‰§è¡Œå¤±è´¥: {e}")
                continue
        
        self.logger.info(f"ğŸ“‹ æ€»å…±æ”¶é›† {len(all_raw_data)} æ¡åŸå§‹æ•°æ®")
        
        # å¤„ç†åŸå§‹æ•°æ®
        processed_data = self.data_processor.process_raw_data(all_raw_data, "commodity")
        
        # éªŒè¯æ•°æ®
        valid_data, invalid_data = self.data_validator.validate_data_list(processed_data)
        
        # å»é‡åˆå¹¶
        merged_data = self.data_processor.merge_duplicate_data(valid_data)
        
        self.logger.info(f"ğŸ‰ æ•°æ®æ”¶é›†å®Œæˆ: æœ‰æ•ˆ {len(merged_data)} æ¡")
        
        if invalid_data:
            self.logger.warning(f"âš ï¸ å‘ç° {len(invalid_data)} æ¡æ— æ•ˆæ•°æ®")
            validation_summary = self.data_validator.get_validation_summary(invalid_data)
            self.logger.info(f"éªŒè¯æ‘˜è¦: {validation_summary}")
        
        return merged_data
    
    def get_commodity_by_category(self, commodities: List[CommodityData]) -> Dict[str, List[CommodityData]]:
        """
        æŒ‰åˆ†ç±»åˆ†ç»„å•†å“æ•°æ®
        
        Args:
            commodities: å•†å“æ•°æ®åˆ—è¡¨
            
        Returns:
            Dict[str, List[CommodityData]]: æŒ‰åˆ†ç±»åˆ†ç»„çš„å•†å“æ•°æ®
        """
        categories = {}
        
        for commodity in commodities:
            category = commodity.category or "å…¶ä»–"
            if category not in categories:
                categories[category] = []
            categories[category].append(commodity)
        
        # æŒ‰ä»·æ ¼æ’åºæ¯ä¸ªåˆ†ç±»
        for category in categories:
            categories[category].sort(key=lambda x: x.current_price or 0, reverse=True)
        
        return categories
    
    def get_top_performers(self, commodities: List[CommodityData], limit: int = 10) -> Dict[str, List[CommodityData]]:
        """
        è·å–è¡¨ç°æœ€ä½³çš„å•†å“
        
        Args:
            commodities: å•†å“æ•°æ®åˆ—è¡¨
            limit: è¿”å›æ•°é‡é™åˆ¶
            
        Returns:
            Dict: åŒ…å«æ¶¨å¹…æœ€å¤§å’Œè·Œå¹…æœ€å¤§çš„å•†å“
        """
        # è¿‡æ»¤æœ‰å˜åŒ–ç™¾åˆ†æ¯”çš„å•†å“
        commodities_with_change = [c for c in commodities if c.change_percent is not None]
        
        # æ¶¨å¹…æœ€å¤§
        top_gainers = sorted(
            commodities_with_change, 
            key=lambda x: x.change_percent, 
            reverse=True
        )[:limit]
        
        # è·Œå¹…æœ€å¤§
        top_losers = sorted(
            commodities_with_change, 
            key=lambda x: x.change_percent
        )[:limit]
        
        return {
            'top_gainers': top_gainers,
            'top_losers': top_losers
        }
    
    def generate_market_summary(self, commodities: List[CommodityData]) -> Dict[str, Any]:
        """
        ç”Ÿæˆå¸‚åœºæ‘˜è¦
        
        Args:
            commodities: å•†å“æ•°æ®åˆ—è¡¨
            
        Returns:
            Dict: å¸‚åœºæ‘˜è¦ä¿¡æ¯
        """
        if not commodities:
            return {"error": "æ— å•†å“æ•°æ®"}
        
        # åŸºæœ¬ç»Ÿè®¡
        total_commodities = len(commodities)
        commodities_with_change = [c for c in commodities if c.change_percent is not None]
        
        if commodities_with_change:
            avg_change = sum(c.change_percent for c in commodities_with_change) / len(commodities_with_change)
            gainers = len([c for c in commodities_with_change if c.change_percent > 0])
            losers = len([c for c in commodities_with_change if c.change_percent < 0])
            unchanged = len(commodities_with_change) - gainers - losers
        else:
            avg_change = 0
            gainers = losers = unchanged = 0
        
        # æŒ‰åˆ†ç±»ç»Ÿè®¡
        categories = self.get_commodity_by_category(commodities)
        category_stats = {}
        
        for category, items in categories.items():
            items_with_change = [c for c in items if c.change_percent is not None]
            if items_with_change:
                cat_avg_change = sum(c.change_percent for c in items_with_change) / len(items_with_change)
            else:
                cat_avg_change = 0
            
            category_stats[category] = {
                'count': len(items),
                'avg_change': round(cat_avg_change, 2)
            }
        
        # è¡¨ç°æœ€ä½³
        performers = self.get_top_performers(commodities, 5)
        
        return {
            'summary': {
                'total_commodities': total_commodities,
                'avg_change_percent': round(avg_change, 2),
                'gainers': gainers,
                'losers': losers,
                'unchanged': unchanged,
                'data_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            },
            'category_stats': category_stats,
            'top_performers': {
                'top_gainers': [
                    {
                        'name': c.name,
                        'chinese_name': c.chinese_name,
                        'change_percent': c.change_percent,
                        'current_price': c.current_price
                    } for c in performers['top_gainers']
                ],
                'top_losers': [
                    {
                        'name': c.name,
                        'chinese_name': c.chinese_name,
                        'change_percent': c.change_percent,
                        'current_price': c.current_price
                    } for c in performers['top_losers']
                ]
            }
        }
    
    def save_to_csv(self, commodities: List[CommodityData], filename: Optional[str] = None) -> Path:
        """ä¿å­˜ä¸ºCSVæ–‡ä»¶"""
        if not filename:
            timestamp = datetime.now().strftime(self.config.output.timestamp_format)
            filename = f"commodity_data_{timestamp}.csv"
        
        filepath = self.output_dir / filename
        
        csv_writer = CSVWriter()
        csv_writer.write_commodity_data(commodities, filepath)
        
        self.logger.info(f"ğŸ’¾ CSVæ–‡ä»¶å·²ä¿å­˜: {filepath}")
        return filepath
    
    def save_to_excel(self, commodities: List[CommodityData], filename: Optional[str] = None) -> Path:
        """ä¿å­˜ä¸ºExcelæ–‡ä»¶"""
        if not filename:
            timestamp = datetime.now().strftime(self.config.output.timestamp_format)
            filename = f"commodity_data_{timestamp}.xlsx"
        
        filepath = self.output_dir / filename
        
        excel_writer = ExcelWriter()
        excel_writer.write_commodity_data(commodities, filepath)
        
        self.logger.info(f"ğŸ’¾ Excelæ–‡ä»¶å·²ä¿å­˜: {filepath}")
        return filepath
    
    def run_full_analysis(self, scraper_names: Optional[List[str]] = None) -> Dict[str, Any]:
        """
        è¿è¡Œå®Œæ•´çš„å•†å“æ•°æ®åˆ†æ
        
        Args:
            scraper_names: è¦ä½¿ç”¨çš„çˆ¬è™«åç§°åˆ—è¡¨
            
        Returns:
            Dict: åˆ†æç»“æœ
        """
        self.logger.info("ğŸ¯ å¼€å§‹å®Œæ•´å•†å“æ•°æ®åˆ†æ")
        
        # æ”¶é›†æ•°æ®
        commodities = self.collect_all_commodity_data(scraper_names)
        
        if not commodities:
            self.logger.error("âŒ æœªè·å–åˆ°ä»»ä½•å•†å“æ•°æ®")
            return {"error": "æœªè·å–åˆ°å•†å“æ•°æ®"}
        
        # ç”Ÿæˆæ‘˜è¦
        summary = self.generate_market_summary(commodities)
        
        # ä¿å­˜æ–‡ä»¶
        csv_file = self.save_to_csv(commodities)
        excel_file = self.save_to_excel(commodities)
        
        self.logger.info("âœ… å®Œæ•´åˆ†æå®Œæˆ")
        
        return {
            'commodities': commodities,
            'summary': summary,
            'files': {
                'csv': str(csv_file),
                'excel': str(excel_file)
            }
        } 