#!/usr/bin/env python3
"""
Pacong çˆ¬è™«ç³»ç»Ÿä¸»å…¥å£
æ¨¡å—åŒ–å•†å“æ•°æ®çˆ¬å–ç³»ç»Ÿ
"""

import argparse
import sys
from pathlib import Path
from typing import List, Optional

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from pacong.core import init_config, init_logging, get_logger
from pacong.services import CommodityService
from pacong.scrapers import ScraperFactory


def setup_argument_parser() -> argparse.ArgumentParser:
    """è®¾ç½®å‘½ä»¤è¡Œå‚æ•°è§£æå™¨"""
    parser = argparse.ArgumentParser(
        description="ğŸš€ Pacong - æ™ºèƒ½æ•°æ®çˆ¬å–ç³»ç»Ÿ",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ğŸ¯ å¿«é€Ÿå¼€å§‹:
  %(prog)s                                    # è¿è¡Œæ‰€æœ‰æ•°æ®æº
  %(prog)s --scrapers business_insider        # è¿è¡Œç‰¹å®šæ•°æ®æº
  %(prog)s --list-scrapers                    # æŸ¥çœ‹å¯ç”¨æ•°æ®æº
  %(prog)s --log-level DEBUG                  # è°ƒè¯•æ¨¡å¼

ğŸ“ æ·»åŠ æ–°æ•°æ®æº: ç¼–è¾‘ config/settings.yaml
ğŸ“Š æŸ¥çœ‹ç»“æœ: ls reports/
        """
    )
    
    parser.add_argument(
        '--config', '-c',
        type=str,
        help='é…ç½®æ–‡ä»¶è·¯å¾„'
    )
    
    parser.add_argument(
        '--scrapers', '-s',
        nargs='+',
        help='è¦ä½¿ç”¨çš„çˆ¬è™«åç§°åˆ—è¡¨'
    )
    
    parser.add_argument(
        '--list-scrapers',
        action='store_true',
        help='åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„çˆ¬è™«'
    )
    
    parser.add_argument(
        '--output-dir', '-o',
        type=str,
        help='è¾“å‡ºç›®å½•è·¯å¾„'
    )
    
    parser.add_argument(
        '--log-level',
        choices=['DEBUG', 'INFO', 'WARNING', 'ERROR'],
        default='INFO',
        help='æ—¥å¿—çº§åˆ«'
    )
    
    parser.add_argument(
        '--quiet', '-q',
        action='store_true',
        help='é™é»˜æ¨¡å¼ï¼Œåªè¾“å‡ºé”™è¯¯'
    )
    
    parser.add_argument(
        '--version', '-v',
        action='version',
        version='Pacong 2.0 - æ¨¡å—åŒ–çˆ¬è™«ç³»ç»Ÿ'
    )
    
    return parser


def validate_scrapers(scraper_names: List[str]) -> List[str]:
    """éªŒè¯çˆ¬è™«åç§°"""
    available_scrapers = ScraperFactory.list_available_scrapers()
    invalid_scrapers = [name for name in scraper_names if name not in available_scrapers]
    
    if invalid_scrapers:
        print(f"âŒ æ— æ•ˆçš„çˆ¬è™«åç§°: {', '.join(invalid_scrapers)}")
        print(f"ğŸ“‹ å¯ç”¨çˆ¬è™«: {', '.join(available_scrapers)}")
        sys.exit(1)
    
    return scraper_names


def list_scrapers():
    """åˆ—å‡ºæ‰€æœ‰å¯ç”¨çˆ¬è™«"""
    scrapers = ScraperFactory.list_available_scrapers()
    
    print("ğŸ“‹ å¯ç”¨çˆ¬è™«åˆ—è¡¨:")
    print("=" * 50)
    
    if not scrapers:
        print("âŒ æœªæ‰¾åˆ°ä»»ä½•å·²æ³¨å†Œçš„çˆ¬è™«")
        return
    
    for i, scraper_name in enumerate(scrapers, 1):
        print(f"{i}. {scraper_name}")
    
    print(f"\næ€»è®¡: {len(scrapers)} ä¸ªçˆ¬è™«")


def print_summary(result: dict):
    """æ‰“å°åˆ†ææ‘˜è¦"""
    if 'error' in result:
        print(f"âŒ é”™è¯¯: {result['error']}")
        return
    
    summary = result.get('summary', {})
    main_summary = summary.get('summary', {})
    category_stats = summary.get('category_stats', {})
    top_performers = summary.get('top_performers', {})
    
    print("\n" + "=" * 60)
    print("ğŸ“Š å•†å“æ•°æ®åˆ†æç»“æœæ‘˜è¦")
    print("=" * 60)
    
    # åŸºæœ¬ç»Ÿè®¡
    print(f"ğŸ“ˆ æ€»å•†å“æ•°: {main_summary.get('total_commodities', 0)}")
    print(f"ğŸ“Š å¹³å‡æ¶¨è·Œå¹…: {main_summary.get('avg_change_percent', 0):.2f}%")
    print(f"ğŸŸ¢ ä¸Šæ¶¨å•†å“: {main_summary.get('gainers', 0)}")
    print(f"ğŸ”´ ä¸‹è·Œå•†å“: {main_summary.get('losers', 0)}")
    print(f"âšª æŒå¹³å•†å“: {main_summary.get('unchanged', 0)}")
    print(f"ğŸ• æ•°æ®æ—¶é—´: {main_summary.get('data_time', 'N/A')}")
    
    # åˆ†ç±»ç»Ÿè®¡
    if category_stats:
        print(f"\nğŸ“‹ åˆ†ç±»ç»Ÿè®¡:")
        for category, stats in category_stats.items():
            print(f"  {category}: {stats['count']} ä¸ª (å¹³å‡æ¶¨è·Œ: {stats['avg_change']:.2f}%)")
    
    # è¡¨ç°æœ€ä½³
    if top_performers:
        top_gainers = top_performers.get('top_gainers', [])
        top_losers = top_performers.get('top_losers', [])
        
        if top_gainers:
            print(f"\nğŸš€ æ¶¨å¹…æ¦œå‰5:")
            for i, item in enumerate(top_gainers[:5], 1):
                print(f"  {i}. {item['chinese_name']} ({item['name']}): +{item['change_percent']:.2f}%")
        
        if top_losers:
            print(f"\nğŸ“‰ è·Œå¹…æ¦œå‰5:")
            for i, item in enumerate(top_losers[:5], 1):
                print(f"  {i}. {item['chinese_name']} ({item['name']}): {item['change_percent']:.2f}%")
    
    # æ–‡ä»¶ä¿¡æ¯
    files = result.get('files', {})
    if files:
        print(f"\nğŸ’¾ è¾“å‡ºæ–‡ä»¶:")
        for file_type, file_path in files.items():
            print(f"  {file_type.upper()}: {file_path}")


def main():
    """ä¸»å‡½æ•°"""
    parser = setup_argument_parser()
    args = parser.parse_args()
    
    try:
        # åˆå§‹åŒ–é…ç½®
        if args.config:
            config = init_config(args.config)
        else:
            config = init_config()
        
        # è¦†ç›–é…ç½®
        if args.output_dir:
            config.set('output.reports_dir', args.output_dir)
        
        if args.quiet:
            config.set('logging.level', 'ERROR')
        elif args.log_level:
            config.set('logging.level', args.log_level)
        
        # åˆå§‹åŒ–æ—¥å¿—
        logger = init_logging()
        
        # æ‰“å°æ¬¢è¿ä¿¡æ¯
        if not args.quiet:
            print("ğŸ¯ Pacong æ¨¡å—åŒ–å•†å“æ•°æ®çˆ¬å–ç³»ç»Ÿ")
            print("=" * 50)
            print("ğŸ“Š é€šè¿‡æ¨¡å—åŒ–æ¶æ„æä¾›å…¨é¢çš„å•†å“æ•°æ®")
            print()
        
        # å¤„ç†å‘½ä»¤
        if args.list_scrapers:
            list_scrapers()
            return
        
        # éªŒè¯çˆ¬è™«åç§°
        scraper_names = None
        if args.scrapers:
            scraper_names = validate_scrapers(args.scrapers)
            logger.info(f"ä½¿ç”¨æŒ‡å®šçˆ¬è™«: {', '.join(scraper_names)}")
        
        # åˆ›å»ºæœåŠ¡å¹¶è¿è¡Œåˆ†æ
        commodity_service = CommodityService()
        result = commodity_service.run_full_analysis(scraper_names)
        
        # æ‰“å°ç»“æœ
        if not args.quiet:
            print_summary(result)
        
        logger.info("ğŸ‰ ç³»ç»Ÿè¿è¡Œå®Œæˆ")
        
    except KeyboardInterrupt:
        print("\nâš ï¸ ç”¨æˆ·ä¸­æ–­æ“ä½œ")
        sys.exit(1)
    except Exception as e:
        print(f"âŒ ç³»ç»Ÿé”™è¯¯: {e}")
        if not args.quiet:
            import traceback
            traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main() 