#!/usr/bin/env python3
"""
æ•´åˆå•†å“æ•°æ®çˆ¬è™«
åŒæ—¶ä»Business Insiderå’ŒBloombergè·å–æ•°æ®ï¼Œå¹¶æ•´åˆåˆ°ä¸€ä¸ªExcelæ–‡ä»¶ä¸­
"""

import requests
import subprocess
import time
import logging
from pathlib import Path
import pandas as pd
from datetime import datetime
from bs4 import BeautifulSoup
import numpy as np

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class IntegratedCommoditiesScraper:
    def __init__(self):
        self.output_dir = Path("reports")
        self.output_dir.mkdir(exist_ok=True)
        
        # å•†å“åç§°æ˜ å°„ï¼Œç”¨äºåŒ¹é…ä¸åŒç½‘ç«™çš„åŒä¸€å•†å“
        self.commodity_mapping = {
            # Business Insider -> Bloomberg
            'Gold': ['GC1:COM', 'XAUUSD:CUR'],
            'Silver': ['SI1:COM'],
            'Platinum': ['XPTUSD:CUR'],
            'Copper': ['HG1:COM'],
            'Oil (WTI)': ['CL1:COM'],
            'Oil (Brent)': ['CO1:COM'],
            'Natural Gas': ['NG1:COM'],
            'Natural Gas (Henry Hub)': ['NG1:COM'],
            'RBOB Gasoline': ['XB1:COM'],
            'Heating Oil': ['HO1:COM'],
            'Corn': ['C 1:COM'],
            'Wheat': ['W 1:COM'],
            'Cocoa': ['CC1:COM'],
            'Cotton': ['CT1:COM'],
            'Live Cattle': ['LC1:COM'],
        }
        
        # ä¸­æ–‡åç§°ç»Ÿä¸€å¯¹ç…§
        self.chinese_names = {
            'Gold': 'é»„é‡‘',
            'Silver': 'ç™½é“¶',
            'Platinum': 'é“‚é‡‘',
            'Palladium': 'é’¯é‡‘',
            'Copper': 'é“œ',
            'Oil (WTI)': 'WTIåŸæ²¹',
            'Oil (Brent)': 'å¸ƒä¼¦ç‰¹åŸæ²¹',
            'Natural Gas': 'å¤©ç„¶æ°”',
            'Natural Gas (Henry Hub)': 'å¤©ç„¶æ°”',
            'RBOB Gasoline': 'RBOBæ±½æ²¹',
            'Heating Oil': 'å–æš–æ²¹',
            'Corn': 'ç‰ç±³',
            'Wheat': 'å°éº¦',
            'Cocoa': 'å¯å¯',
            'Cotton': 'æ£‰èŠ±',
            'Live Cattle': 'æ´»ç‰›',
            'Coffee': 'å’–å•¡',
            'Sugar': 'ç³–',
            'Lumber': 'æœ¨æ',
        }

    def scrape_business_insider(self):
        """çˆ¬å–Business Insideræ•°æ®"""
        logger.info("ğŸ” å¼€å§‹çˆ¬å–Business Insideræ•°æ®...")
        
        url = "https://markets.businessinsider.com/commodities"
        headers = {
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
            'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
            'Accept-Encoding': 'gzip, deflate, br',
            'Connection': 'keep-alive',
        }
        
        try:
            response = requests.get(url, headers=headers, timeout=30)
            if response.status_code == 200:
                soup = BeautifulSoup(response.content, 'html.parser')
                commodities = []
                
                tables = soup.find_all('table')
                logger.info(f"Business Insider: å‘ç° {len(tables)} ä¸ªæ•°æ®è¡¨æ ¼")
                
                for table in tables:
                    rows = table.find_all('tr')
                    
                    for row in rows:
                        cells = row.find_all(['td', 'th'])
                        if len(cells) >= 3:
                            cell_texts = [cell.get_text(strip=True) for cell in cells]
                            
                            name = cell_texts[0]
                            if (name and len(name) > 2 and not name.isdigit() and
                                'commodity' not in name.lower() and 'price' not in name.lower()):
                                
                                price = None
                                change = None
                                
                                for text in cell_texts[1:]:
                                    if re.search(r'\d+\.?\d*', text) and price is None:
                                        price_match = re.search(r'(\d+,?\d*\.?\d*)', text.replace(',', ''))
                                        if price_match:
                                            try:
                                                price = float(price_match.group(1))
                                            except ValueError:
                                                continue
                                    
                                    if ('%' in text or '+' in text or '-' in text) and change is None:
                                        change = text
                                
                                if name and price is not None:
                                    commodities.append({
                                        'name': name,
                                        'chinese_name': self.chinese_names.get(name, name),
                                        'price': price,
                                        'change': change,
                                        'source': 'Business Insider',
                                        'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                                    })
                
                logger.info(f"âœ… Business Insider: æˆåŠŸè·å– {len(commodities)} æ¡æ•°æ®")
                return commodities
            else:
                logger.error(f"âŒ Business Insiderè®¿é—®å¤±è´¥: {response.status_code}")
                return []
                
        except Exception as e:
            logger.error(f"âŒ Business Insiderçˆ¬å–å¤±è´¥: {e}")
            return []

    def execute_applescript(self, script: str) -> str:
        """æ‰§è¡ŒAppleScriptè„šæœ¬"""
        try:
            process = subprocess.run(
                ['osascript', '-e', script],
                capture_output=True,
                text=True,
                check=True,
                timeout=60
            )
            if process.stderr:
                logger.warning(f"AppleScriptè­¦å‘Š: {process.stderr}")
            return process.stdout.strip()
        except subprocess.CalledProcessError as e:
            logger.error(f"AppleScriptæ‰§è¡Œå¤±è´¥: {e.stderr}")
            raise
        except Exception as e:
            logger.error(f"AppleScriptå¼‚å¸¸: {e}")
            raise

    def scrape_bloomberg(self):
        """çˆ¬å–Bloombergæ•°æ®"""
        logger.info("ğŸ” å¼€å§‹çˆ¬å–Bloombergæ•°æ®...")
        
        bloomberg_translations = {
            'BCOMTR:IND': 'å½­åšå•†å“æŒ‡æ•°',
            'CMCITR:IND': 'UBSå½­åšCMCIæŒ‡æ•°',
            'CRYTR:IND': 'è·¯é€/æ°å¯Œç‘CRBæŒ‡æ•°',
            'RICIGLTR:IND': 'ç½—æ°æ–¯å›½é™…å•†å“æŒ‡æ•°',
            'SPGSCITR:IND': 'æ ‡æ™®GSCIæŒ‡æ•°',
            'CL1:COM': 'WTIåŸæ²¹æœŸè´§',
            'CO1:COM': 'å¸ƒä¼¦ç‰¹åŸæ²¹æœŸè´§',
            'XB1:COM': 'RBOBæ±½æ²¹æœŸè´§',
            'NG1:COM': 'å¤©ç„¶æ°”æœŸè´§',
            'HO1:COM': 'å–æš–æ²¹æœŸè´§',
            'GC1:COM': 'é»„é‡‘æœŸè´§',
            'XAUUSD:CUR': 'é»„é‡‘ç°è´§',
            'SI1:COM': 'ç™½é“¶æœŸè´§',
            'HG1:COM': 'é“œæœŸè´§',
            'XPTUSD:CUR': 'é“‚é‡‘ç°è´§',
            'C 1:COM': 'ç‰ç±³æœŸè´§',
            'W 1:COM': 'å°éº¦æœŸè´§',
            'CC1:COM': 'å¯å¯æœŸè´§',
            'CT1:COM': 'æ£‰èŠ±æœŸè´§',
            'LC1:COM': 'æ´»ç‰›æœŸè´§',
        }
        
        try:
            url = "https://www.bloomberg.com/markets/commodities"
            
            # ä½¿ç”¨AppleScriptæ§åˆ¶Chrome
            logger.info("ä½¿ç”¨Chromeæ‰“å¼€Bloombergé¡µé¢...")
            open_script = f'tell application "Google Chrome" to open location "{url}"'
            self.execute_applescript(open_script)

            # è°ƒæ•´çª—å£å¤§å°
            time.sleep(2)
            try:
                resize_script = '''
                tell application "Finder" to get bounds of window of desktop
                set screenDimensions to the result
                set screenWidth to item 3 of screenDimensions
                set screenHeight to item 4 of screenDimensions
                
                tell application "Google Chrome"
                    activate
                    try
                        set bounds of front window to {screenWidth - 1, screenHeight - 1, screenWidth, screenHeight}
                    on error
                        set bounds of front window to {100, 100, 101, 101}
                    end try
                end tell
                '''
                self.execute_applescript(resize_script)
            except Exception as e:
                logger.warning(f"çª—å£è°ƒæ•´å¤±è´¥: {e}")

            # ç­‰å¾…é¡µé¢åŠ è½½
            logger.info("ç­‰å¾…Bloombergé¡µé¢åŠ è½½...")
            time.sleep(15)

            # æ»šåŠ¨é¡µé¢
            try:
                for i in range(3):  # å‡å°‘æ»šåŠ¨æ¬¡æ•°ä»¥åŠ å¿«é€Ÿåº¦
                    scroll_script = 'tell application "Google Chrome" to execute active tab of front window javascript "window.scrollBy(0, window.innerHeight);"'
                    self.execute_applescript(scroll_script)
                    time.sleep(1)
                time.sleep(3)
            except Exception as e:
                logger.warning(f"æ»šåŠ¨å¤±è´¥: {e}")

            # è·å–é¡µé¢HTML
            logger.info("è·å–Bloombergé¡µé¢å†…å®¹...")
            get_html_script = 'tell application "Google Chrome" to execute active tab of front window javascript "document.documentElement.outerHTML"'
            html_content = self.execute_applescript(get_html_script)
            
            if not html_content:
                logger.error("æœªèƒ½è·å–Bloomberg HTMLå†…å®¹")
                return []

            # è§£ææ•°æ®
            soup = BeautifulSoup(html_content, 'lxml')
            commodities = []

            price_cells = soup.find_all('td', class_='data-table-row-cell', attrs={'data-type': 'value'})
            logger.info(f"Bloomberg: æ‰¾åˆ° {len(price_cells)} ä¸ªä»·æ ¼å•å…ƒæ ¼")

            for cell in price_cells:
                row = cell.find_parent('tr')
                if not row:
                    continue

                name_cell = row.find(['td', 'th'], class_='data-table-row-cell', attrs={'data-type': 'name'})
                price_span = cell.find('span', class_='data-table-row-cell__value')
                
                if not (name_cell and price_span):
                    continue
                
                try:
                    name_div = name_cell.find('div', class_='data-table-row-cell__link-block')
                    symbol = name_div.get_text(strip=True) if name_div else name_cell.get_text(strip=True)
                    
                    price_str = price_span.get_text(strip=True).replace(',', '')
                    price = float(price_str)

                    if symbol and price is not None:
                        chinese_name = bloomberg_translations.get(symbol, symbol)
                        
                        commodities.append({
                            'name': symbol,
                            'chinese_name': chinese_name,
                            'price': price,
                            'change': None,  # Bloombergæ¶¨è·Œå¹…æå–è¾ƒå¤æ‚ï¼Œæš‚æ—¶è®¾ä¸ºNone
                            'source': 'Bloomberg',
                            'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                        })
                        
                except (ValueError, TypeError, AttributeError) as e:
                    continue
            
            logger.info(f"âœ… Bloomberg: æˆåŠŸè·å– {len(commodities)} æ¡æ•°æ®")
            return commodities

        except Exception as e:
            logger.error(f"âŒ Bloombergçˆ¬å–å¤±è´¥: {e}")
            return []

    def create_integrated_excel(self, bi_data, bloomberg_data):
        """åˆ›å»ºæ•´åˆçš„ExcelæŠ¥å‘Š"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        excel_file = self.output_dir / f"integrated_commodities_{timestamp}.xlsx"
        
        try:
            with pd.ExcelWriter(excel_file, engine='openpyxl') as writer:
                
                # å·¥ä½œè¡¨1: Business Insideræ•°æ®
                if bi_data:
                    bi_df = pd.DataFrame(bi_data)
                    bi_df.to_excel(writer, sheet_name='Business Insider', index=False)
                    logger.info(f"Business Insideræ•°æ®å†™å…¥Excel: {len(bi_data)}æ¡")
                
                # å·¥ä½œè¡¨2: Bloombergæ•°æ®
                if bloomberg_data:
                    bloomberg_df = pd.DataFrame(bloomberg_data)
                    bloomberg_df.to_excel(writer, sheet_name='Bloomberg', index=False)
                    logger.info(f"Bloombergæ•°æ®å†™å…¥Excel: {len(bloomberg_data)}æ¡")
                
                # å·¥ä½œè¡¨3: æ•°æ®å¯¹æ¯”
                comparison_data = self.create_comparison_data(bi_data, bloomberg_data)
                if comparison_data:
                    comparison_df = pd.DataFrame(comparison_data)
                    comparison_df.to_excel(writer, sheet_name='ä»·æ ¼å¯¹æ¯”', index=False)
                    logger.info(f"ä»·æ ¼å¯¹æ¯”æ•°æ®å†™å…¥Excel: {len(comparison_data)}æ¡")
                
                # å·¥ä½œè¡¨4: æ±‡æ€»ç»Ÿè®¡
                summary_data = self.create_summary_data(bi_data, bloomberg_data)
                if summary_data:
                    summary_df = pd.DataFrame(summary_data)
                    summary_df.to_excel(writer, sheet_name='æ•°æ®æ±‡æ€»', index=False)
                    logger.info("æ•°æ®æ±‡æ€»å†™å…¥Excel")
                
                # å·¥ä½œè¡¨5: åˆå¹¶æ•°æ®
                merged_data = self.merge_all_data(bi_data, bloomberg_data)
                if merged_data:
                    merged_df = pd.DataFrame(merged_data)
                    merged_df.to_excel(writer, sheet_name='å…¨éƒ¨æ•°æ®', index=False)
                    logger.info(f"å…¨éƒ¨æ•°æ®å†™å…¥Excel: {len(merged_data)}æ¡")
            
            logger.info(f"âœ… æ•´åˆExcelæ–‡ä»¶å·²ç”Ÿæˆ: {excel_file}")
            return excel_file
            
        except Exception as e:
            logger.error(f"âŒ ç”ŸæˆExcelæ–‡ä»¶å¤±è´¥: {e}")
            return None

    def create_comparison_data(self, bi_data, bloomberg_data):
        """åˆ›å»ºä»·æ ¼å¯¹æ¯”æ•°æ®"""
        comparison = []
        
        # åˆ›å»ºBloombergæ•°æ®çš„å¿«é€ŸæŸ¥æ‰¾å­—å…¸
        bloomberg_dict = {}
        for item in bloomberg_data:
            bloomberg_dict[item['name']] = item
        
        # éå†Business Insideræ•°æ®ï¼Œå¯»æ‰¾å¯å¯¹æ¯”çš„Bloombergæ•°æ®
        for bi_item in bi_data:
            bi_name = bi_item['name']
            
            # æŸ¥æ‰¾å¯¹åº”çš„Bloombergå•†å“
            bloomberg_matches = self.commodity_mapping.get(bi_name, [])
            
            for bloomberg_symbol in bloomberg_matches:
                if bloomberg_symbol in bloomberg_dict:
                    bloomberg_item = bloomberg_dict[bloomberg_symbol]
                    
                    # è®¡ç®—ä»·æ ¼å·®å¼‚
                    bi_price = bi_item['price']
                    bloomberg_price = bloomberg_item['price']
                    price_diff = bi_price - bloomberg_price
                    price_diff_percent = (price_diff / bloomberg_price * 100) if bloomberg_price != 0 else 0
                    
                    comparison.append({
                        'å•†å“åç§°': self.chinese_names.get(bi_name, bi_name),
                        'Business Insiderè‹±æ–‡å': bi_name,
                        'Bloombergä»£ç ': bloomberg_symbol,
                        'BIä»·æ ¼': bi_price,
                        'Bloombergä»·æ ¼': bloomberg_price,
                        'ä»·æ ¼å·®å¼‚': round(price_diff, 2),
                        'å·®å¼‚ç™¾åˆ†æ¯”': f"{price_diff_percent:.2f}%",
                        'BIæ¶¨è·Œå¹…': bi_item.get('change', 'N/A'),
                        'BIæ—¶é—´': bi_item['timestamp'],
                        'Bloombergæ—¶é—´': bloomberg_item['timestamp']
                    })
                    break  # æ‰¾åˆ°ç¬¬ä¸€ä¸ªåŒ¹é…å°±è·³å‡º
        
        return comparison

    def create_summary_data(self, bi_data, bloomberg_data):
        """åˆ›å»ºæ±‡æ€»ç»Ÿè®¡æ•°æ®"""
        summary = [
            {'æŒ‡æ ‡': 'æ•°æ®æº', 'Business Insider': 'Business Insider', 'Bloomberg': 'Bloomberg'},
            {'æŒ‡æ ‡': 'æ•°æ®æ¡æ•°', 'Business Insider': len(bi_data), 'Bloomberg': len(bloomberg_data)},
            {'æŒ‡æ ‡': 'æ•°æ®è·å–æ—¶é—´', 'Business Insider': datetime.now().strftime('%Y-%m-%d %H:%M:%S'), 'Bloomberg': datetime.now().strftime('%Y-%m-%d %H:%M:%S')},
            {'æŒ‡æ ‡': 'çˆ¬å–æ–¹å¼', 'Business Insider': 'HTTPè¯·æ±‚', 'Bloomberg': 'AppleScript+Chrome'},
            {'æŒ‡æ ‡': 'æ•°æ®å®Œæ•´æ€§', 'Business Insider': 'åŒ…å«ä»·æ ¼å’Œæ¶¨è·Œå¹…', 'Bloomberg': 'ä»…åŒ…å«ä»·æ ¼'},
            {'æŒ‡æ ‡': 'æŠ€æœ¯éš¾åº¦', 'Business Insider': 'ç®€å•', 'Bloomberg': 'å¤æ‚'},
            {'æŒ‡æ ‡': 'å¯å¯¹æ¯”å•†å“æ•°', 'Business Insider': '-', 'Bloomberg': str(len(self.create_comparison_data(bi_data, bloomberg_data)))},
        ]
        
        # è®¡ç®—ä»·æ ¼ç»Ÿè®¡
        if bi_data:
            bi_prices = [item['price'] for item in bi_data]
            summary.extend([
                {'æŒ‡æ ‡': 'BIå¹³å‡ä»·æ ¼', 'Business Insider': f"${np.mean(bi_prices):.2f}", 'Bloomberg': '-'},
                {'æŒ‡æ ‡': 'BIæœ€é«˜ä»·æ ¼', 'Business Insider': f"${max(bi_prices):.2f}", 'Bloomberg': '-'},
                {'æŒ‡æ ‡': 'BIæœ€ä½ä»·æ ¼', 'Business Insider': f"${min(bi_prices):.2f}", 'Bloomberg': '-'},
            ])
        
        if bloomberg_data:
            bloomberg_prices = [item['price'] for item in bloomberg_data]
            summary.extend([
                {'æŒ‡æ ‡': 'Bloombergå¹³å‡ä»·æ ¼', 'Business Insider': '-', 'Bloomberg': f"${np.mean(bloomberg_prices):.2f}"},
                {'æŒ‡æ ‡': 'Bloombergæœ€é«˜ä»·æ ¼', 'Business Insider': '-', 'Bloomberg': f"${max(bloomberg_prices):.2f}"},
                {'æŒ‡æ ‡': 'Bloombergæœ€ä½ä»·æ ¼', 'Business Insider': '-', 'Bloomberg': f"${min(bloomberg_prices):.2f}"},
            ])
        
        return summary

    def merge_all_data(self, bi_data, bloomberg_data):
        """åˆå¹¶æ‰€æœ‰æ•°æ®"""
        merged = []
        
        # æ·»åŠ Business Insideræ•°æ®
        for item in bi_data:
            merged.append({
                'æ•°æ®æº': 'Business Insider',
                'å•†å“åç§°': item['name'],
                'ä¸­æ–‡åç§°': item['chinese_name'],
                'ä»·æ ¼': item['price'],
                'æ¶¨è·Œå¹…': item.get('change', 'N/A'),
                'æ—¶é—´æˆ³': item['timestamp']
            })
        
        # æ·»åŠ Bloombergæ•°æ®
        for item in bloomberg_data:
            merged.append({
                'æ•°æ®æº': 'Bloomberg',
                'å•†å“åç§°': item['name'],
                'ä¸­æ–‡åç§°': item['chinese_name'],
                'ä»·æ ¼': item['price'],
                'æ¶¨è·Œå¹…': item.get('change', 'N/A'),
                'æ—¶é—´æˆ³': item['timestamp']
            })
        
        return merged

    def run_integrated_scraping(self):
        """è¿è¡Œæ•´åˆçˆ¬å–"""
        print("ğŸš€ å¯åŠ¨æ•´åˆå•†å“æ•°æ®çˆ¬å–ç³»ç»Ÿ")
        print("="*60)
        print("ğŸ“Š å°†åŒæ—¶ä»Business Insiderå’ŒBloombergè·å–æ•°æ®")
        print("ğŸ’¾ å¹¶æ•´åˆåˆ°ä¸€ä¸ªExcelæ–‡ä»¶ä¸­è¿›è¡Œå¯¹æ¯”åˆ†æ")
        print()
        
        # 1. çˆ¬å–Business Insideræ•°æ®
        print("1ï¸âƒ£ çˆ¬å–Business Insideræ•°æ®...")
        bi_data = self.scrape_business_insider()
        
        # 2. çˆ¬å–Bloombergæ•°æ®
        print("\n2ï¸âƒ£ çˆ¬å–Bloombergæ•°æ®...")
        print("âš ï¸ è¯·ç¡®ä¿Google Chromeæµè§ˆå™¨æ­£åœ¨è¿è¡Œ")
        bloomberg_data = self.scrape_bloomberg()
        
        # 3. ç”Ÿæˆæ•´åˆExcel
        print("\n3ï¸âƒ£ ç”Ÿæˆæ•´åˆExcelæŠ¥å‘Š...")
        excel_file = self.create_integrated_excel(bi_data, bloomberg_data)
        
        # 4. æ˜¾ç¤ºç»“æœæ‘˜è¦
        print("\n" + "="*60)
        print("ğŸ“Š æ•°æ®çˆ¬å–ç»“æœæ‘˜è¦")
        print("="*60)
        print(f"ğŸ“ˆ Business Insider: {len(bi_data)} æ¡æ•°æ®")
        print(f"ğŸ“ˆ Bloomberg: {len(bloomberg_data)} æ¡æ•°æ®")
        print(f"ğŸ“Š æ€»è®¡: {len(bi_data) + len(bloomberg_data)} æ¡æ•°æ®")
        
        if excel_file:
            print(f"\nâœ… æ•´åˆExcelæ–‡ä»¶å·²ç”Ÿæˆ: {excel_file}")
            print("\nğŸ“‹ ExcelåŒ…å«ä»¥ä¸‹å·¥ä½œè¡¨:")
            print("   1. Business Insider - BIåŸå§‹æ•°æ®")
            print("   2. Bloomberg - BloombergåŸå§‹æ•°æ®") 
            print("   3. ä»·æ ¼å¯¹æ¯” - ç›¸åŒå•†å“ä»·æ ¼å¯¹æ¯”")
            print("   4. æ•°æ®æ±‡æ€» - ç»Ÿè®¡ä¿¡æ¯æ±‡æ€»")
            print("   5. å…¨éƒ¨æ•°æ® - æ‰€æœ‰æ•°æ®åˆå¹¶")
            
            # æ˜¾ç¤ºå¯å¯¹æ¯”çš„å•†å“
            comparison_data = self.create_comparison_data(bi_data, bloomberg_data)
            if comparison_data:
                print(f"\nğŸ” å‘ç° {len(comparison_data)} ä¸ªå¯å¯¹æ¯”çš„å•†å“:")
                for comp in comparison_data[:5]:  # æ˜¾ç¤ºå‰5ä¸ª
                    print(f"   â€¢ {comp['å•†å“åç§°']}: BI ${comp['BIä»·æ ¼']:.2f} vs Bloomberg ${comp['Bloombergä»·æ ¼']:.2f}")
            
            return True
        else:
            print("âŒ Excelæ–‡ä»¶ç”Ÿæˆå¤±è´¥")
            return False

def main():
    """ä¸»å‡½æ•°"""
    scraper = IntegratedCommoditiesScraper()
    scraper.run_integrated_scraping()

if __name__ == "__main__":
    import re  # æ·»åŠ ç¼ºå¤±çš„import
    main() 